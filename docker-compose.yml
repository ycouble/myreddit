version: "3.4"

services:

  #traefik:
    #image: 'traefik:latest'
    #certificat ssl

  # cubejs:
  #   build:
  #     context: ./cubejs
  #   depends_on:
  #     - dagster
  #     - ...
  #   ports:
  #     - 80:4000
  #   volumes:
  #    - name
  #      container:volume

  # This service runs the postgres DB used by dagster for run storage, schedule storage,
  # and event log storage.
  dagster_postgresql:
    image: postgres:11
    container_name: dagster_postgresql
    environment:
      POSTGRES_USER: ${DAGSTER_POSTGRES_USER}
      POSTGRES_PASSWORD: ${DAGSTER_POSTGRES_PASSWORD}
      POSTGRES_DB: ${DAGSTER_POSTGRES_DB}
    networks:
      - dagster_network

  # This service runs the gRPC server that loads and executes your user code, in both dagit
  # and dagster-daemon. By setting DAGSTER_CURRENT_IMAGE to its own image, we tell the
  # run launcher to use this same image when launching runs in a new container as well.
  # Multiple containers like this can be deployed separately - each just needs to run on
  # its own port, and have its own entry in the workspace.yaml file that's loaded by dagit.
  dagster_user_code:
    build:
      context: .
      dockerfile: ./Dockerfile_user_code
      args:
        - GCP_DBT_KEY_PATH=${GCP_DBT_KEY_PATH}
    container_name: dagster_user_code
    image: dagster_user_code_image
    restart: always
    environment:
      DAGSTER_POSTGRES_USER: ${DAGSTER_POSTGRES_USER}
      DAGSTER_POSTGRES_PASSWORD: ${DAGSTER_POSTGRES_PASSWORD}
      DAGSTER_POSTGRES_DB: ${DAGSTER_POSTGRES_DB}
      DAGSTER_CURRENT_IMAGE: ${DAGSTER_CURRENT_IMAGE}
      GCP_DBT_KEY_PATH: ${GCP_DBT_KEY_PATH}
      RUBRIX_API_URL: http://rubrix:80
    volumes:
      - ./dags:/opt/dagster/app
      - ./dbt:/opt/dagster/dbt
      - ./models:/opt/dagster/models
      - ./spacy_configs:/opt/dagster/spacy_configs
    networks:
      - dagster_network

  # This service runs dagit, which loads the user code from the user code container.
  # Since our instance uses the QueuedRunCoordinator, any runs submitted from dagit will be put on
  # a queue and later dequeued and launched by dagster-daemon.
  dagster_dagit:
    build:
      context: .
      dockerfile: ./Dockerfile_dagster
    entrypoint:
      - dagit
      - -h
      - "0.0.0.0"
      - -p
      - "3000"
      - -w
      - workspace.yaml
    container_name: dagster_dagit
    expose:
      - "3000"
    ports:
      - "3000:3000"
    environment:
      DAGSTER_POSTGRES_USER: ${DAGSTER_POSTGRES_USER}
      DAGSTER_POSTGRES_PASSWORD: ${DAGSTER_POSTGRES_PASSWORD}
      DAGSTER_POSTGRES_DB: ${DAGSTER_POSTGRES_DB}
    volumes: # Make docker client accessible so we can terminate containers from dagit
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - dagster_network
    depends_on:
      - dagster_postgresql
      - dagster_user_code

  # This service runs the dagster-daemon process, which is responsible for taking runs
  # off of the queue and launching them, as well as creating runs from schedules or sensors.
  dagster_daemon:
    build:
      context: .
      dockerfile: ./Dockerfile_dagster
    entrypoint:
      - dagster-daemon
      - run
    container_name: dagster_daemon
    restart: on-failure
    environment:
      DAGSTER_POSTGRES_USER: ${DAGSTER_POSTGRES_USER}
      DAGSTER_POSTGRES_PASSWORD: ${DAGSTER_POSTGRES_PASSWORD}
      DAGSTER_POSTGRES_DB: ${DAGSTER_POSTGRES_DB}
    volumes: # Make docker client accessible so we can launch containers using host docker
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - dagster_network
    depends_on:
      - dagster_postgresql
      - dagster_user_code

  rubrix:
    image: recognai/rubrix:v0.10.0
    container_name: rubrix
    ports:
      - "6900:80"
    environment:
      ELASTICSEARCH: elasticsearch:9200
    #   RUBRIX_LOCAL_AUTH_USERS_DB_FILE: /config/.users.yaml
    # volumes:
    #   - ${PWD}/.users.yaml:/config/.users.yaml
    networks:
      - rubrix_network
      - dagster_network
    depends_on:
      - elasticsearch

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.11.1
    container_name: elasticsearch
    environment:
      - node.name=elasticsearch
      - cluster.name=es-rubrix-local
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    networks:
      - rubrix_network
    volumes:
      - ./es_data:/usr/share/elasticsearch/data

  kibana:
    image: docker.elastic.co/kibana/kibana:7.11.1
    container_name: kibana
    ports:
      - 5601:5601
    environment:
      ELASTICSEARCH_URL: http://elasticsearch:9200
      ELASTICSEARCH_HOSTS: '["http://elasticsearch:9200"]'
    networks:
      - rubrix_network

networks:
  dagster_network:
    driver: bridge
    name: dagster_network
  rubrix_network:
    driver: bridge
