{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve data and create make_doc function to format examples for spacy pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "key_path = \"/Users/yco/.dbt/dbt-user-creds.json\"\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    key_path#, scopes=[\"https://www.googleapis.com/auth/cloud-platform\"],\n",
    ")\n",
    "\n",
    "client = bigquery.Client(credentials=credentials, project=credentials.project_id,)\n",
    "query = \"SELECT * from `reddit_texts.posts_clean`\"\n",
    "query_job = client.query(query)\n",
    "\n",
    "texts = []\n",
    "labels = []\n",
    "ids = []\n",
    "for row in query_job:\n",
    "    ids.append(row[\"id\"])\n",
    "    texts.append(row['text'])\n",
    "    labels.append(row['subreddit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LanguageTechnology', 'dataengineering', 'datasets'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats = set(labels)\n",
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from spacy.tokens import DocBin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(list(zip(texts, ids)), labels, test_size=0.2)\n",
    "text_train, ids_train = list(zip(*X_train))\n",
    "train_data = list(zip(text_train, zip(ids_train, y_train)))\n",
    "text_valid, ids_valid = list(zip(*X_valid))\n",
    "valid_data = list(zip(text_valid, zip(ids_valid, y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_docs(data, tgt_file):\n",
    "    docs = DocBin()\n",
    "    for doc, (_, label) in nlp.pipe(data, as_tuples=True):\n",
    "        for cat in cats:\n",
    "            doc.cats[cat] = 1 if cat == label else 0\n",
    "        docs.add(doc)\n",
    "    docs.to_disk(tgt_file)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_docs = make_docs(train_data, \"tmp/train.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Created output directory: ../models/default_textcat/2022/01/21\u001b[0m\n",
      "\u001b[38;5;4mℹ Saving to output directory: ../models/default_textcat/2022/01/21\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTCAT  CATS_SCORE  SCORE \n",
      "---  ------  ------------  ----------  ------\n",
      "  0       0          0.67        1.67    0.02\n",
      "  0     200         89.10       55.92    0.56\n",
      "  1     400         36.52       74.81    0.75\n",
      "  2     600         10.67       77.68    0.78\n",
      "  3     800          3.71       75.40    0.75\n",
      "  4    1000          2.76       75.77    0.76\n",
      "  5    1200          4.43       75.77    0.76\n",
      "  6    1400          0.29       74.74    0.75\n",
      "  8    1600          4.11       74.92    0.75\n",
      " 10    1800          4.11       75.90    0.76\n",
      " 12    2000          0.37       77.49    0.77\n",
      " 15    2200          0.46       77.11    0.77\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "../models/default_textcat/2022/01/21/model-last\n"
     ]
    }
   ],
   "source": [
    "from spacy.cli.train import train\n",
    "import datetime\n",
    "\n",
    "train(\n",
    "    \"../spacy_configs/subreddit_classif/default_textcat.cfg\",\n",
    "    output_path=f\"../models/default_textcat/{datetime.date.today().strftime('%Y/%m/%d')}\",\n",
    "    overrides={\n",
    "        \"paths.train\": \"tmp/train.spacy\", \n",
    "        \"paths.dev\": \"tmp/valid.spacy\", \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_folder = Path(\"../models/\")\n",
    "def get_latest_model(model_name: str) -> Path:\n",
    "    model_folder = models_folder / model_name\n",
    "    for level in [\"year\", \"month\", \"day\"]:\n",
    "        model_folder = model_folder / max(x.name for x in model_folder.iterdir() if x.is_dir())\n",
    "    return model_folder\n",
    "\n",
    "nlp_textcat = spacy.load(str(get_latest_model(\"default_textcat\") / \"model-best\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Are there any datasets out there of antlered big game? Specifically, I am looking for images of deer/elk/moose/sheep after they've been shot.\n",
      "datasets\n",
      "{'dataengineering': 0.22329650819301605, 'datasets': 0.5606533885002136, 'LanguageTechnology': 0.21605007350444794}\n",
      "---\n",
      "e.g. Top Medium authors, blogs, newsletters, etc.\n",
      "dataengineering\n",
      "{'dataengineering': 0.2881203591823578, 'datasets': 0.4115089774131775, 'LanguageTechnology': 0.3003706634044647}\n",
      "---\n",
      "Hello all,\n",
      "I'm trying to get smarter on mimicing writing style based on sample input text. The hope is a system like this:\n",
      "**Inputs:**\n",
      "* Input tagged sample writing/letters/emails/dialogue from desired author.\n",
      "* Basic sentence to be rewrite .\n",
      "**Output:**\n",
      "* Translated sentence written in sample author's writing style.\n",
      "I'm assuming this is a bit of an ambitious lift and may require some training on my own. Curious if anyone has any insights on stylometry papers written. Even something on generative text that is just meant to replicate an author's style could be a helpful starting point.\n",
      "Thanks!\n",
      "LanguageTechnology\n",
      "{'dataengineering': 0.10544515401124954, 'datasets': 0.04374290257692337, 'LanguageTechnology': 0.8508118987083435}\n"
     ]
    }
   ],
   "source": [
    "for text, cat in valid_data[:3]:\n",
    "    doc = nlp_textcat(text)\n",
    "    print(\"---\", doc, cat, doc.cats, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cats_score': 0.8161111111111111,\n",
       " 'cats_score_desc': 'macro F',\n",
       " 'cats_micro_p': 0.8375,\n",
       " 'cats_micro_r': 0.8375,\n",
       " 'cats_micro_f': 0.8375,\n",
       " 'cats_macro_p': 0.8398290598290599,\n",
       " 'cats_macro_r': 0.8027038183694529,\n",
       " 'cats_macro_f': 0.8161111111111111,\n",
       " 'cats_macro_auc': 0.9410453912559177,\n",
       " 'cats_f_per_type': {'dataengineering': {'p': 0.8333333333333334,\n",
       "   'r': 0.9210526315789473,\n",
       "   'f': 0.875},\n",
       "  'datasets': {'p': 0.84, 'r': 0.84, 'f': 0.8399999999999999},\n",
       "  'LanguageTechnology': {'p': 0.8461538461538461,\n",
       "   'r': 0.6470588235294118,\n",
       "   'f': 0.7333333333333334}},\n",
       " 'cats_auc_per_type': {'dataengineering': 0.9505012531328322,\n",
       "  'datasets': 0.952,\n",
       "  'LanguageTechnology': 0.9206349206349207}}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.training import Example\n",
    "from spacy.scorer import Scorer\n",
    "\n",
    "def score_text_cat(model_name, data):\n",
    "    nlp_textcat = spacy.load(str(get_latest_model(model_name) / \"model-best\"))\n",
    "    examples = []\n",
    "    for doc, label in nlp_textcat.pipe(data, as_tuples=True):\n",
    "        examples.append(Example.from_dict(doc, {\"cats\": {cat: 1 if cat == label else 0 for cat in cats}}))\n",
    "\n",
    "    scorer = Scorer(nlp_textcat)\n",
    "    scores = scorer.score_cats(examples, \"cats\", labels=cats, multi_label=False)\n",
    "    return scores\n",
    "\n",
    "score_text_cat(\"default_textcat\", valid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'datasets',\n",
       "  'date': '2022-01-21',\n",
       "  'pred': 'datasets',\n",
       "  'confidence': 0.5606533885002136},\n",
       " {'id': 'dataengineering',\n",
       "  'date': '2022-01-21',\n",
       "  'pred': 'datasets',\n",
       "  'confidence': 0.4115089774131775},\n",
       " {'id': 'LanguageTechnology',\n",
       "  'date': '2022-01-21',\n",
       "  'pred': 'LanguageTechnology',\n",
       "  'confidence': 0.8508118987083435},\n",
       " {'id': 'dataengineering',\n",
       "  'date': '2022-01-21',\n",
       "  'pred': 'dataengineering',\n",
       "  'confidence': 0.760303258895874}]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def batch_predict(model_name, data):\n",
    "    date = datetime.date.today().strftime(\"%Y-%m-%d\")\n",
    "    nlp_textcat = spacy.load(str(get_latest_model(model_name) / \"model-best\"))\n",
    "    predictions = []\n",
    "    for doc, _id in nlp_textcat.pipe(data, as_tuples=True):\n",
    "        predicted_cat = max(doc.cats, key=lambda x: doc.cats[x])\n",
    "        predictions.append({\"id\": _id, \"date\": date, \"pred\": predicted_cat, \"confidence\": doc.cats[predicted_cat]})\n",
    "    return predictions\n",
    "\n",
    "batch_predict(\"default_textcat\", valid_data[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myreddit",
   "language": "python",
   "name": "myreddit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
